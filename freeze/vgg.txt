2021-01-12 14:49:01 | number: 1 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 3.3162457093479127 0.47945137052085457 0.3979662358760834 0.66437006 0.7637795 0.8214285969734192 0.8527272727272728 0.32432432432432434 0.2 0.8571428571428571 328100 296870 
1 0.38945072208802534 0.5642596882159315 0.448638916015625 0.8366142 0.77165353 0.8214285969734192 0.879090909090909 0.2857142857142857 0.16666666666666666 1.0 78111 640625 
2 0.3791295412018543 0.44320932898934434 0.36715736985206604 0.84547246 0.7992126 0.8428571224212646 0.8924242424242425 0.4210526315789474 0.26666666666666666 1.0 62483 656248 
3 0.2806272614659287 0.3215075639758523 0.3318541944026947 0.90059054 0.86220473 0.8642857074737549 0.9045454545454547 0.7246376811594204 0.8333333333333334 0.6410256410256411 62485 640624 
4 0.3199206547239634 0.6141190918411795 0.4860248565673828 0.867126 0.79527557 0.8428571224212646 0.9109090909090909 0.4210526315789474 0.26666666666666666 1.0 78111 624997 
5 0.2512010037312357 0.45193403677677546 0.4965497553348541 0.8927165 0.8110236 0.7857142686843872 0.9184848484848485 0.6428571428571429 0.9 0.5 46876 624995 
6 0.28122969605321957 0.29440689274645226 0.2622310221195221 0.88385826 0.8543307 0.8999999761581421 0.9227272727272727 0.7307692307692307 0.6333333333333333 0.8636363636363636 78113 624999 
7 0.2016853556975605 0.29099513860199394 0.28087592124938965 0.9261811 0.87007874 0.8999999761581421 0.9254545454545455 0.7741935483870969 0.8 0.75 62487 656246 
8 0.14801320762146175 0.27206523164989443 0.24721260368824005 0.9478347 0.86614174 0.9142857193946838 0.9318181818181818 0.7857142857142856 0.7333333333333333 0.8461538461538461 46862 640624 
9 0.19957224473239868 0.4113663679032814 0.31634148955345154 0.9360236 0.81496066 0.8571428656578064 0.9324242424242424 0.5 0.3333333333333333 1.0 62503 640623 
2021-01-12 14:51:05 | number: 2 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 0.49479005327374914 0.3016666903739839 0.36016789078712463 0.8651575 0.8267717 0.8428571224212646 0.9266666666666666 0.4210526315789474 0.26666666666666666 1.0 156233 640619 
1 0.281248911393909 0.2654253862739548 0.38224664330482483 0.878937 0.8503937 0.8500000238418579 0.9284848484848485 0.4615384615384615 0.3 1.0 46858 640621 
2 0.2229089797951105 0.33435292530247546 0.5075718760490417 0.91043305 0.8464567 0.7928571701049805 0.9318181818181819 0.6588235294117647 0.9333333333333333 0.509090909090909 109364 624999 
3 0.22312876611478685 0.18931605438078483 0.30605459213256836 0.9133858 0.88582677 0.8785714507102966 0.9321212121212121 0.6046511627906976 0.43333333333333335 1.0 78126 656224 
4 0.14394398414947857 0.08529404832387534 0.23942841589450836 0.94586617 0.96850395 0.9142857193946838 0.9369696969696969 0.8064516129032259 0.8333333333333334 0.78125 109363 624999 
5 0.08630574078071775 0.13622141834788434 0.30882057547569275 0.9675197 0.9488189 0.8999999761581421 0.9403030303030304 0.7083333333333334 0.5666666666666667 0.9444444444444444 78110 656226 
6 0.07463355591212671 0.10499739687977813 0.261174738407135 0.97047246 0.95669293 0.9214285612106323 0.9390909090909091 0.8070175438596491 0.7666666666666667 0.8518518518518519 93718 687495 
7 0.060307358860910876 0.11968306496035395 0.3181512653827667 0.9773622 0.95669293 0.8928571343421936 0.9390909090909091 0.7761194029850748 0.8666666666666667 0.7027027027027027 62489 671877 
8 0.07328326987674622 0.2160378258059344 0.39008060097694397 0.97244096 0.9251968 0.8928571343421936 0.9345454545454546 0.6666666666666666 0.5 1.0 78110 671871 
9 0.22104249021962402 0.18898362038642402 0.3204943537712097 0.93307084 0.9409449 0.8857142925262451 0.9396969696969696 0.7714285714285714 0.9 0.675 31221 703128 
2021-01-12 14:53:09 | number: 3 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 0.170973021581065 0.27775725217785424 0.43662264943122864 0.9301181 0.88188976 0.8642857074737549 0.9387878787878787 0.5365853658536585 0.36666666666666664 1.0 328111 671875 
1 0.14314614547284568 0.10947166436065839 0.27363675832748413 0.9468504 0.9527559 0.8999999761581421 0.9375757575757576 0.7083333333333334 0.5666666666666667 0.9444444444444444 171845 671873 
2 0.061137350232113065 0.07458833827248473 0.2749740183353424 0.9773622 0.96850395 0.9285714030265808 0.936969696969697 0.8148148148148148 0.7333333333333333 0.9166666666666666 78110 671855 
3 0.0462213149110926 0.03861213281868011 0.3529373109340668 0.9812992 0.988189 0.8928571343421936 0.9418181818181818 0.7826086956521738 0.9 0.6923076923076923 46846 687492 
4 0.17432635658105292 0.12823444816071217 0.34912970662117004 0.9360236 0.96850395 0.8999999761581421 0.939090909090909 0.8 0.9333333333333333 0.7 46847 687480 
5 0.05986361812770836 0.0625865643946674 0.3165735602378845 0.9832677 0.97637796 0.8928571343421936 0.9412121212121213 0.7826086956521738 0.9 0.6923076923076923 46877 687497 
6 0.09122336721121091 0.07791255205488345 0.2570851147174835 0.9576772 0.96850395 0.9214285612106323 0.943939393939394 0.8 0.7333333333333333 0.88 62503 671887 
7 0.01912056270566967 0.08353792198413 0.2855359613895416 0.99704725 0.97244096 0.9357143044471741 0.9436363636363636 0.8363636363636363 0.7666666666666667 0.92 62486 671872 
8 0.026764190532120428 0.0421819660123291 0.27309879660606384 0.98917323 0.988189 0.9142857193946838 0.9445454545454546 0.8000000000000002 0.8 0.8 46864 656248 
9 0.005500602750400976 0.040524113002988534 0.29801198840141296 1.0 0.984252 0.9214285612106323 0.9448484848484849 0.819672131147541 0.8333333333333334 0.8064516129032258 46864 687497 
2021-01-12 14:55:12 | number: 4 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 0.03431069478392601 0.03803877135020072 0.5364238619804382 0.9901575 0.984252 0.8785714507102966 0.9412121212121212 0.767123287671233 0.9333333333333333 0.6511627906976745 359361 687482 
1 0.13031694021691956 0.06755101384492371 0.42687535285949707 0.9517717 0.98031497 0.8857142925262451 0.9418181818181819 0.7777777777777778 0.9333333333333333 0.6666666666666666 156237 703106 
2 0.030718260510699955 0.01665759728268141 0.29250621795654297 0.992126 1.0 0.9214285612106323 0.9448484848484848 0.8307692307692307 0.9 0.7714285714285715 109376 703123 
3 0.017827500880688546 0.006946930977127214 0.2613510489463806 0.99507874 1.0 0.9214285612106323 0.9478787878787879 0.819672131147541 0.8333333333333334 0.8064516129032258 109363 718748 
4 0.007650878304234288 0.03204301709499885 0.3106032907962799 0.99901575 0.984252 0.9071428775787354 0.9466666666666667 0.7547169811320754 0.6666666666666666 0.8695652173913043 140597 953122 
5 0.005596211748188508 0.005947035913333649 0.2766193747520447 0.99901575 1.0 0.9285714030265808 0.9457575757575758 0.8275862068965518 0.8 0.8571428571428571 109372 640626 
6 0.0027584682776057344 0.003670118639142964 0.2922353148460388 1.0 1.0 0.9214285612106323 0.9463636363636364 0.819672131147541 0.8333333333333334 0.8064516129032258 46861 624992 
7 0.0015675182019793026 0.0034697142798145574 0.33444085717201233 1.0 1.0 0.9285714030265808 0.9463636363636363 0.84375 0.9 0.7941176470588235 81381 624996 
8 0.0016921112867526887 0.004734864539107469 0.30334722995758057 1.0 1.0 0.9285714030265808 0.9463636363636364 0.8275862068965518 0.8 0.8571428571428571 78094 640633 
9 0.0011708124519663123 0.002428907056808413 0.3160807490348816 1.0 1.0 0.9214285612106323 0.9463636363636363 0.819672131147541 0.8333333333333334 0.8064516129032258 93736 640606 
2021-01-12 14:57:14 | number: 5 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 0.0013076535762493006 0.0005401953382006897 0.33249711990356445 1.0 1.0 0.9357143044471741 0.946969696969697 0.8571428571428572 0.9 0.8181818181818182 124987 640617 
1 0.0011133035460641006 0.0005423628060994156 0.3423651456832886 1.0 1.0 0.9357143044471741 0.946969696969697 0.8571428571428572 0.9 0.8181818181818182 93753 687497 
2 0.0011464239672875018 0.00032359592806305884 0.3246202766895294 1.0 1.0 0.9214285612106323 0.9475757575757575 0.819672131147541 0.8333333333333334 0.8064516129032258 93737 687499 
3 0.0010600577937677415 0.00029413160736448915 0.3287021219730377 1.0 1.0 0.9214285612106323 0.9478787878787879 0.819672131147541 0.8333333333333334 0.8064516129032258 93719 671871 
4 0.0008972575134088057 0.0002687011369207038 0.32981348037719727 1.0 1.0 0.9214285612106323 0.9478787878787879 0.819672131147541 0.8333333333333334 0.8064516129032258 78114 687499 
5 0.0004255957633355911 0.00026455516885694734 0.3430042564868927 1.0 1.0 0.9285714030265808 0.9478787878787879 0.8387096774193549 0.8666666666666667 0.8125 46859 656239 
6 0.00036577441029279954 0.00025535277622627225 0.3478725552558899 1.0 1.0 0.9285714030265808 0.9475757575757575 0.8387096774193549 0.8666666666666667 0.8125 31233 671873 
7 0.00032062435478676023 0.00021217984315117925 0.3425537347793579 1.0 1.0 0.9285714030265808 0.9475757575757576 0.8387096774193549 0.8666666666666667 0.8125 62485 656247 
8 0.00031509243458780774 0.00021580998999145483 0.35112473368644714 1.0 1.0 0.9285714030265808 0.9475757575757576 0.8387096774193549 0.8666666666666667 0.8125 46878 640623 
9 0.0002898409123684639 0.0002210142439704271 0.3576948940753937 1.0 1.0 0.9285714030265808 0.9475757575757576 0.8387096774193549 0.8666666666666667 0.8125 62504 671873 
