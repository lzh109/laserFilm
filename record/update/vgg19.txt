2021-01-12 17:05:59 | number: 6 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 211.31806775012353 0.5623275980236023 0.5306157469749451 0.7332677 0.7598425 0.7857142686843872 0.33454545454545453 0.0 0.0 0.0 472184 811351 
1 0.5918789658490129 0.8992603031669076 0.8022675514221191 0.7805118 0.7598425 0.7857142686843872 0.283030303030303 0.0 0.0 0.0 3228 692766 
2 0.5209956131582185 0.5791547490855841 0.5344851613044739 0.7942913 0.7598425 0.7857142686843872 0.6524242424242425 0.0 0.0 0.0 960677 681787 
3 0.5256333093004902 0.5563672719977972 0.520327627658844 0.7923228 0.7598425 0.7857142686843872 0.44984848484848483 0.0 0.0 0.0 4562 674832 
4 0.5312662960037472 0.567999015642902 0.5267053246498108 0.7942913 0.7598425 0.7857142686843872 0.6836363636363637 0.0 0.0 0.0 30852 706771 
5 0.5126357104365281 0.594544210771876 0.5449526906013489 0.7942913 0.7598425 0.7857142686843872 0.2993939393939394 0.0 0.0 0.0 8389 696412 
6 0.6353374175199373 0.5484481214538334 0.5198500752449036 0.7942913 0.7598425 0.7857142686843872 0.7021212121212121 0.0 0.0 0.0 264755 683765 
7 0.5138768253363962 0.5726035270165271 0.5297726392745972 0.7942913 0.7598425 0.7857142686843872 0.5945454545454546 0.0 0.0 0.0 133204 683714 
8 0.5083252477833605 0.551151008117856 0.5204299688339233 0.7942913 0.7598425 0.7857142686843872 0.7175757575757576 0.0 0.0 0.0 73924 682698 
9 0.5168535714074383 0.5510816752441287 0.5211467742919922 0.7942913 0.7598425 0.7857142686843872 0.669090909090909 0.0 0.0 0.0 85421 682782 
10 0.5429680173791299 0.5641623261406665 0.542435348033905 0.7598425 0.7598425 0.7857142686843872 0.33606060606060606 0.0 0.0 0.0 51546 716679 
11 0.5228862297816539 0.5507490095191114 0.5185749530792236 0.7942913 0.7598425 0.7857142686843872 0.5354545454545454 0.0 0.0 0.0 140673 700661 
12 0.5146043319401779 0.5494921071322885 0.5200361609458923 0.7942913 0.7598425 0.7857142686843872 0.6642424242424242 0.0 0.0 0.0 531745 680479 
13 0.5129305757875517 0.5554051108247652 0.5199268460273743 0.7942913 0.7598425 0.7857142686843872 0.6536363636363637 0.0 0.0 0.0 911405 718764 
14 0.5097060933357148 0.5517229986941721 0.5194953680038452 0.7942913 0.7598425 0.7857142686843872 0.66 0.0 0.0 0.0 49109 690767 
15 0.5099160905898087 0.567172529659872 0.5261090397834778 0.7942913 0.7598425 0.7857142686843872 0.6633333333333333 0.0 0.0 0.0 163649 803832 
16 0.5097773546778311 0.551287793268369 0.5192758440971375 0.7942913 0.7598425 0.7857142686843872 0.6696969696969698 0.0 0.0 0.0 36734 682451 
17 0.5145569518795163 0.5520882127791877 0.5253997445106506 0.7942913 0.7598425 0.7857142686843872 0.6703030303030303 0.0 0.0 0.0 804629 704760 
18 0.5096772360050772 0.5509790768773537 0.5199384093284607 0.7942913 0.7598425 0.7857142686843872 0.6754545454545454 0.0 0.0 0.0 928281 718716 
19 0.5084536608279221 0.5565134427678866 0.5200967192649841 0.7942913 0.7598425 0.7857142686843872 0.677878787878788 0.0 0.0 0.0 873066 705549 
2021-01-12 17:12:03 | number: 7 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 46.78561650298712 0.5559925939154438 0.5544413924217224 0.64665353 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 527862 816737 
1 0.5237299048994469 0.522610078881106 0.5198018550872803 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 933580 716322 
2 0.5170630549821328 0.5225656067761849 0.5197402238845825 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 918484 705773 
3 0.5164610422033025 0.5250302351365878 0.5217408537864685 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 976992 694832 
4 0.5191965046830065 0.5233708268075478 0.5202457904815674 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 933276 687765 
5 0.5189388793284498 0.524116868109215 0.5209075808525085 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 19552 685769 
6 0.5215608813161925 0.5258947880718652 0.5225416421890259 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 848393 701681 
7 0.5185421238264699 0.5254513931086683 0.5221298336982727 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 863002 702450 
8 0.5165549751341812 0.5246485495191859 0.5221090912818909 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 959145 733765 
9 0.5199293428518641 0.5231432609670744 0.5200505256652832 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 985776 716691 
10 0.5184498375325691 0.5229568633976884 0.5202297568321228 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 876497 900710 
11 0.518228372250955 0.5226283418381308 0.5198262333869934 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 912503 672622 
12 0.5175336876253444 0.5227892610031789 0.5200293660163879 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 858442 633798 
13 0.5175867040795604 0.5233407867705728 0.520219624042511 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 825779 669244 
14 0.517478176458614 0.5278798696093672 0.5244050025939941 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 856631 697809 
15 0.5210162023390372 0.5232362301330867 0.5201295614242554 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 115405 727636 
16 0.5168253549440639 0.5230883977075261 0.5203829407691956 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 3267 705242 
17 0.5189105868339539 0.5286867207898869 0.5251686573028564 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 971220 681585 
18 0.5169358070441118 0.5243129310176129 0.5217451453208923 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 36720 703789 
19 0.5197516449793117 0.5265528662936894 0.5231563448905945 0.7883858 0.78346455 0.7857142686843872 0.5 0.0 0.0 0.0 995318 688958 
2021-01-12 17:18:24 | number: 8 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 26.781503236669256 0.5200189657098665 0.5494147539138794 0.7234252 0.8228347 0.7857142686843872 0.31878787878787873 0.0 0.0 0.0 524665 817438 
1 0.597048346451887 0.5485011503452392 0.5698021054267883 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 920766 685783 
2 0.5416469142192931 0.47044151739811335 0.5196362137794495 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 893118 694693 
3 0.531011259931279 0.47122562706001164 0.519580602645874 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 924315 687396 
4 0.5307902618656009 0.4751180764727705 0.520196259021759 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 862903 684958 
5 0.5299550416901355 0.4724392700852372 0.5196440815925598 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 874935 698138 
6 0.5308907313609686 0.47040028506376613 0.5196418762207031 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 947290 670896 
7 0.5301616266956479 0.4757746458053589 0.5203917622566223 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 897082 696765 
8 0.5304274084999805 0.4748358900152792 0.5201182961463928 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 871714 690607 
9 0.529902006697467 0.4786066886946911 0.5214210152626038 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 975820 710382 
10 0.5307528916306383 0.47294245343508684 0.5197110176086426 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 810258 707277 
11 0.5299317167969201 0.47183730775915733 0.5195932984352112 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 865719 686065 
12 0.5299666467614061 0.47063754674956554 0.51961350440979 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 7290 725763 
13 0.5288663858503807 0.4760267915218834 0.5204718112945557 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 50317 929977 
14 0.5296006284830138 0.47346556656003935 0.5198010206222534 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 807746 643218 
15 0.5300721878141869 0.4767472384952185 0.5207141041755676 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 848756 659777 
16 0.529898539302856 0.47565866807314355 0.520355761051178 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 956277 674786 
17 0.5292313727806872 0.4692254024227773 0.5199572443962097 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 826602 675768 
18 0.5319838467545397 0.47933120826097925 0.5217235684394836 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 877497 687498 
19 0.5315836475590082 0.47587754618464495 0.5204240679740906 0.7785433 0.8228347 0.7857142686843872 0.5 0.0 0.0 0.0 874987 671875 
2021-01-12 17:24:43 | number: 9 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 30.565875187633544 0.521263647267199 0.5164105296134949 0.73720473 0.77952754 0.7857142686843872 0.6918181818181818 0.0 0.0 0.0 343716 828122 
1 0.6203291805710379 0.5139851868152618 0.5098215341567993 0.78937006 0.77952754 0.7857142686843872 0.73 0.0 0.0 0.0 62485 718744 
2 0.5158767411558647 0.5538098272376173 0.5451387166976929 0.78937006 0.77952754 0.7857142686843872 0.7442424242424244 0.0 0.0 0.0 93722 687494 
3 0.517308968258655 0.5362381470484996 0.5303427577018738 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 78096 718749 
4 0.5168501720653744 0.5295970979637987 0.5208037495613098 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 62472 734371 
5 0.5168239995250552 0.5285066455367982 0.5200183391571045 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 999969 718739 
6 0.5179273105981782 0.527511545992273 0.5197511315345764 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 281218 718746 
7 0.5156749501003055 0.5275771707061707 0.5195842385292053 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 46846 703122 
8 0.5178203822120907 0.5285891125521321 0.5200732350349426 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 999974 718747 
9 0.516598042071335 0.5297721920050974 0.520937979221344 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 953096 703123 
10 0.5166144211461224 0.5275058769804286 0.519709050655365 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 906222 718747 
11 0.5154314454146257 0.5283120626539696 0.5198934674263 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 46871 703106 
12 0.5153593017360357 0.5283355642491439 0.5211248397827148 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 937485 703108 
13 0.519078063683247 0.5280970705775764 0.5197660326957703 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 968741 703123 
14 0.5157451167350678 0.5275765619878694 0.5195843577384949 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 859365 703122 
15 0.5152561704474171 0.5278893160069082 0.5196595788002014 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 843739 703106 
16 0.5157523157559042 0.5275513112075686 0.5195942521095276 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 859358 703121 
17 0.5177988011067308 0.5280049288366723 0.520659863948822 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 937467 687495 
18 0.5178574436292873 0.527646360904213 0.5200825929641724 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 828113 687499 
19 0.5162936754114046 0.5276246629362031 0.5195797681808472 0.78937006 0.77952754 0.7857142686843872 0.5 0.0 0.0 0.0 874969 687500 
2021-01-12 17:31:03 | number: 10 fold
epoch train_loss vali_loss test_loss train_acc vali_acc test_acc test_auc test_f1 test_recall test_precision train_time test_time
0 423.07677865485977 0.7559613651178014 0.7783710360527039 0.6820866 0.79133856 0.7857142686843872 0.7457575757575757 0.0 0.0 0.0 390586 781246 
1 0.5280926438767141 0.5166230541983927 0.5269593596458435 0.7864173 0.79133856 0.7857142686843872 0.7251515151515151 0.0 0.0 0.0 281236 624997 
2 0.5097986178135309 0.5355913838532966 0.5450799465179443 0.7864173 0.79133856 0.7857142686843872 0.7193939393939395 0.0 0.0 0.0 343717 671873 
3 0.5417757686667555 0.5402777612678648 0.5459444522857666 0.7864173 0.79133856 0.7857142686843872 0.7218181818181818 0.0 0.0 0.0 312472 687493 
4 0.506727041925971 0.48339604322365887 0.4928288459777832 0.7864173 0.79133856 0.7857142686843872 0.7303030303030303 0.0 0.0 0.0 328093 703136 
5 0.5043352225164729 0.484967897022803 0.49457022547721863 0.7864173 0.79133856 0.7857142686843872 0.7421212121212121 0.0 0.0 0.0 296851 718748 
6 0.5189820978585191 0.48645872253132616 0.4969959259033203 0.7864173 0.79133856 0.7857142686843872 0.7436363636363637 0.0 0.0 0.0 281217 718750 
7 0.4965603142742097 0.5100992070877646 0.5185715556144714 0.7864173 0.79133856 0.7857142686843872 0.7633333333333333 0.0 0.0 0.0 281221 703107 
8 0.5124364870739734 0.5027182738142689 0.5108446478843689 0.7864173 0.79133856 0.7857142686843872 0.7506060606060606 0.0 0.0 0.0 328096 687496 
9 0.5484554073003334 0.5146822220697178 0.5231760740280151 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 281198 703119 
10 0.5204093543093974 0.5127192580793786 0.5197643041610718 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 312469 656257 
11 0.5199245202729083 0.5128752382721488 0.5198598504066467 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 156200 703127 
12 0.5203352521254322 0.5126484465880656 0.5197238922119141 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 249964 687498 
13 0.5190877144730935 0.5123880083166709 0.520170271396637 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 249955 671871 
14 0.5190534070720823 0.5126595795154572 0.5197300910949707 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 187475 687497 
15 0.5199712848100136 0.5132125470581956 0.5213462710380554 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 281204 671871 
16 0.5196519911758543 0.512402833212079 0.5196076035499573 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 249964 671878 
17 0.5199715945664354 0.5121920557003322 0.519615113735199 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 281204 718748 
18 0.5197325834608454 0.5122026789376116 0.5197977423667908 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 249988 687498 
19 0.5210062884908961 0.512232408748837 0.5198745131492615 0.7864173 0.79133856 0.7857142686843872 0.5 0.0 0.0 0.0 187488 671870 
